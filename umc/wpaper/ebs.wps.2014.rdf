Template-type: ReDIF-Paper 1.0
Title: Inference on Self-Exciting Jumps in Prices and Volatility using High Frequency Measures
Author-Name: Worapree Maneesoonthorn
Author-X-Name-First: Worapree
Author-X-Name-Last: Maneesoonthorn
Author-Email: O.Maneesoonthorn@mbs.edu
Author-Name: Catherine S. Forbes
Author-X-Name-First: Catherine S.
Author-X-Name-Last: Forbes
Author-Email: Catherine.Forbes@monash.edu
Author-Name: Gael M. Martin
Author-X-Name-First: Gael M.
Author-X-Name-Last: Martin
Author-Email: Gael.Martin@monash.edu
Keywords: Dynamic price and volatility jumps; Stochastic volatility; Hawkes process; Nonlinear state space model; Bayesian Markov chain Monte Carlo; Global financial crises
Abstract: Dynamic jumps in the price and volatility of an asset are modelled using a joint Hawkes process in conjunction with a bivariate jump diffusion. A state space representation is used to link observed returns, plus nonparametric measures of integrated volatility and price jumps, to the specified model components; with Bayesian inference conducted using a Markov chain Monte Carlo algorithm. The calculation of marginal likelihoods for the proposed and related models is discussed. An extensive empirical investigation is undertaken using the S&P500 market index, with substantial support for dynamic jump intensities – including in terms of predictive accuracy – documented.
Classification-JEL: C11, C58, G01
Creation-Date: 2014
Number: 30/14
Length: 
Publication-Status: 
File-URL: http://business.monash.edu/__data/assets/pdf_file/0006/327183/wp30-14.pdf
File-Format: application/pdf
Handle: RePEc:msh:ebswps:2014-30

Template-type: ReDIF-Paper 1.0
Title: Applications of Information Measures to Assess Convergence in the Central Limit Theorem
Author-Name: Ranjani Atukorala
Author-X-Name-First: Ranjani
Author-X-Name-Last: Atukorala
Author-Email: ranjani.atukorala@rmit.edu.au
Author-Name: Maxwell L. King
Author-X-Name-First: Maxwell L.
Author-X-Name-Last: King
Author-Email: Maxwell.King@monash.edu
Author-Name: Sivagowry Sriananthakumar
Author-X-Name-First: Sivagowry
Author-X-Name-Last: Sriananthakumar
Author-Email: sivagowry.sriananthakumar@rmit.edu.au
Keywords: Kullback-Leibler Information, Central Limit Theorem, skewness and kurtosis
Abstract: The Central Limit Theorem (CLT) is an important result in statistics and econometrics and econometricians often rely on the CLT for inference in practice. Even though, different conditions apply to different kinds of data, the CLT results are believed to be generally available for a range of situations. This paper illustrates the use of the Kullback-Leibler Information (KLI) measure to assess how close an approximating distribution is to a true distribution in the context of investigating how different population distributions affect convergence in the CLT. For this purpose, three different non-parametric methods for estimating the KLI are proposed and investigated. The main findings of this paper are 1) the distribution of the sample means better approximates the normal distribution as the sample size increases, as expected, 2) for any fixed sample size, the distribution of means of samples from skewed distributions converges faster to the normal distribution as the kurtosis increases, 3) at least in the range of values of kurtosis considered, the distribution of means of small samples generated from symmetric distributions is well approximated by the normal distribution, and 4) among the nonparametric methods used, Vasicek's (1976) estimator seems to be the best for the purpose of assessing asymptotic approximations. Based on the results of the paper, recommendations on minimum sample sizes required for an accurate normal approximation of the true distribution of sample means are made.
Classification-JEL: C1, C2, C4, C5 
Creation-Date: 2014
Number: 29/14
Length: 
Publication-Status: 
File-URL: http://business.monash.edu/__data/assets/pdf_file/0008/327176/wp29-14.pdf
File-Format: application/pdf
Handle: RePEc:msh:ebswps:2014-29


Template-type: ReDIF-Paper 1.0
Title: Bayesian Estimation for Partially Linear Models with an Application to Household Gasoline Consumption
Author-Name: Haotian Chen
Author-X-Name-First: Haotian
Author-X-Name-Last: Chen
Author-Email: Haotian.Chen@monash.edu
Author-Name: Xibin Zhang
Author-X-Name-First: Xibin
Author-X-Name-Last: Zhang
Author-Email: Xibin.Zhang@monash.edu
Keywords: backfitting least squares, bandwidth, household income, price elasticity, profile least squares, random-walk Metropolis
Abstract: A partially linear model is often estimated in a two-stage procedure, which involves estimating the nonlinear component conditional on initially estimated linear coefficients. We propose a sampling procedure that aims to simultaneously estimate the linear coefficients and bandwidths involved in the Nadaraya-Watson estimator of the nonlinear component. The performance of this sampling procedure is demonstrated through Monte Carlo simulation studies. The proposed sampling algorithm is applied to partially linear models of gasoline consumption based on the US household survey data. In contrary to implausible price effect reported in the literature, we find negative price effect on household gasoline consumption.
Classification-JEL: C11, C13, C14, Q41
Creation-Date: 2014
Number: 28/14
Length: 
Publication-Status: 
File-URL: http://business.monash.edu/__data/assets/pdf_file/0004/327145/wp28-14.pdf
File-Format: application/pdf
Handle: RePEc:msh:ebswps:2014-28

Template-type: ReDIF-Paper 1.0
Title: Semiparametric Localized Bandwidth Selection for Kernel Density Estimation
Author-Name: Tingting Cheng
Author-X-Name-First: Tingting
Author-X-Name-Last: Cheng
Author-Email: tingting.cheng@monash.edu
Author-Name: Jiti Gao
Author-X-Name-First: Jiti
Author-X-Name-Last: Gao
Author-Email: jiti.gao@monash.edu
Author-Name: Xibin Zhang
Author-X-Name-First: Xibin
Author-X-Name-Last: Zhang
Author-Email: xibin.zhang@monash.edu
Keywords: Hyperparameter estimation; likelihood function; localized bandwidth.
Abstract: Since conventional cross–validation bandwidth selection methods don’t work for the case where the data considered are dependent time series, alternative bandwidth selection methods are needed. In recent years, Bayesian based global bandwidth selection methods have been proposed. Our experience shows that the use of a global bandwidth is however less suitable than using a localized bandwidth in kernel density estimation in the case where the data are dependent time series as discussed in an empirical application of this paper. Nonetheless, a difficult issue is how we can consistently estimate a localized bandwidth. In this paper, we propose a semiparametric estimation method, for which we establish a completely new asymptotic theory for the proposed semiparametric localized bandwidth estimator. Applications of the new bandwidth estimator to the kernel density estimation of Eurodollar deposit rate and the S&P 500 daily return demonstrate the effectiveness and competitiveness of the proposed semiparametric localized bandwidth.
Classification-JEL: 
Creation-Date: 2014
Number: 27/14
Length: 
Publication-Status: 
File-URL: http://business.monash.edu/econometrics-and-business-statistics/research/publications/ebs/wp27-14.pdf
File-Format: application/pdf
Handle: RePEc:msh:ebswps:2014-27

Template-type: ReDIF-Paper 1.0
Title: High Dimensional Correlation Matrices: CLT and Its Applications
Author-Name: Jiti Gao
Author-X-Name-First: Jiti
Author-X-Name-Last: Gao
Author-Email: jiti.gao@monash.edu
Author-Name: Xiao Han
Author-X-Name-First: Xiao
Author-X-Name-Last: Han
Author-Email: xhan011@e.ntu.edu.sg
Author-Name: Guangming Pan
Author-X-Name-First: Guangming
Author-X-Name-Last: Pan
Author-Email: GMPAN@ntu.edu.sg
Author-Name: Yanrong Yang
Author-X-Name-First: Yanrong
Author-X-Name-Last: Yang
Author-Email: yanrong.yang@monash.edu
Keywords: Central limit theorem; equivalence test; high dimensional correlation matrix; independence test; linear spectral statistics.
Abstract: Statistical inferences for sample correlation matrices are important in high dimensional data analysis. Motivated by this, this paper establishes a new central limit theorem (CLT) for a linear spectral statistic (LSS) of high dimensional sample correlation matrices for the case where the dimension p and the sample size n are comparable. This result is of independent interest in large dimensional random matrix theory. Meanwhile, we apply the linear spectral statistic to an independence test for p random variables, and then an equivalence test for p factor loadings and n factors in a factor model. The finite sample performance of the proposed test shows its applicability and effectiveness in practice. An empirical application to test the independence of household incomes from different cities in China is also conducted.
Classification-JEL: C21, C32 
Creation-Date: 2014
Number: 26/14
Length: 
Publication-Status: 
File-URL: http://business.monash.edu/econometrics-and-business-statistics/research/publications/ebs/wp26-14.pdf
File-Format: application/pdf
Handle: RePEc:msh:ebswps:2014-26

Template-type: ReDIF-Paper 1.0
Title: Nonparametric Regression Approach to Bayesian Estimation
Author-Name: Jiti Gao
Author-X-Name-First: Jiti
Author-X-Name-Last: Gao
Author-Email: Jiti.Gao@monash.edu
Author-Name: Han Hong
Author-X-Name-First: Han
Author-X-Name-Last: Hong
Author-Email: doubleh@stanford.edu
Keywords:  then proposes some non- and semi-parametric dimension reductions methods to deal with the case where the dimensionality of either the regressors or the summary statistics is large. Meanwhile, the paper develops a nonparametric estimation method for the case where the samples are obtained from using a resampling algorithm. The asymptotic theory shows that in each case the rate of convergence of the nonparametric estimate based on the resamples is faster than that of the conventional nonparametric estimation method by an order of the number of the resamples. The proposed models and estimation methods are evaluated through using simulated and empirical examples. Both the simulated and empirical examples show that the proposed nonparametric estimation based on resamples outperforms existing estimation methods.
Abstract: Estimation of unknown parameters and functions involved in complex nonlinear econometric models is a very important issue. Existing estimation methods include generalised method of moments (GMM) by Hansen (1982) and others, efficient method of moments (EMM) by Gallant and Tauchen (1997), Markov chain Monte Carlo (MCMC) method by Chernozhukov and Hong (2003), and nonparametric simulated maximum likelihood estimation (NSMLE) method by Creel and Kristensen (2011), and Kristensen and Shin (2012). Except the NSMLE method, other existing methods do not provide closed-form solutions. This paper proposes non- and semi-parametric based closed-form approximations to the estimation and computation of posterior means involved in complex nonlinear econometric models. We first consider the case where the samples can be independently drawn from both the likelihood function and the prior density. The samples and observations are then used to nonparametrically estimate posterior mean functions. The estimation method is also applied to estimate the posterior mean of the parameter-of-interest on a summary statistic. Both the asymptotic theory and the finite sample study show that the nonparametric estimate of this posterior mean is superior to existing estimates, including the conventional sample mean. 
Classification-JEL: C12, C14, C22
Creation-Date: 2014
Number: 25/14
Length: 
Publication-Status: 
File-URL: http://business.monash.edu/econometrics-and-business-statistics/research/publications/ebs/wp25-14.pdf
File-Format: application/pdf
Handle: RePEc:msh:ebswps:2014-25

Template-type: ReDIF-Paper 1.0
Title: A Computational Implementation of GMM
Author-Name: Jiti Gao
Author-X-Name-First: Jiti
Author-X-Name-Last: Gao
Author-Email: Jiti.Gao@monash.edu
Author-Name: Han Hong
Author-X-Name-First: Han
Author-X-Name-Last: Hong
Author-Email: doubleh@stanford.edu
Keywords: M-estimators, Monte Carlo Markov Chain methods, Nonparametric Regressions.
Abstract: In this paper we study a statistical method of implementing quasi-Bayes estimators for nonlinear and nonseparable GMM models, that is motivated by the ideas proposed in Chernozhukov and Hong (2003) and Creel and Kristensen (2011) and that combines simulation with nonparametric regression in the computation of GMM models. We provide formal conditions under which frequentist inference is asymptotically valid and demonstrate the validity of the use of posterior quantiles. We also show that in this setting, local linear kernel regression methods have theoretical advantages over local kernel methods that are also reflected in finite sample simulation results. Our results also apply to both exactly and over identified models. These estimators do not need to rely on numerical optimization or Markov Chain Monte Carlo simulations. They provide an effective complement to the classical M-estimators and to MCMC methods, and can be applied to both likelihood based models and method of moment based models.
Classification-JEL: C12, C15, C22, C52 
Creation-Date: 2014
Number: 24/14
Length: 
Publication-Status: 
File-URL: http://business.monash.edu/econometrics-and-business-statistics/research/publications/ebs/wp24-14.pdf
File-Format: application/pdf
Handle: RePEc:msh:ebswps:2014-24

Template-type: ReDIF-Paper 1.0
Title: The Effects of Productivity Gains in Asian Emerging Economies: A Global Perspective
Author-Name: Taya Dumrongrittikul
Author-X-Name-First: Taya
Author-X-Name-Last: Dumrongrittikul
Author-Email: taya.dumrongrittikul@anu.edu.au
Author-Name: Heather Anderson
Author-X-Name-First: Heather
Author-X-Name-Last: Anderson
Author-Email: Heather.Anderson@monash.edu
Author-Name: Farshid Vahid
Author-X-Name-First: Farshid
Author-X-Name-Last: Vahid
Author-Email: Farshid.Vahid@monash.edu
Keywords: Asian developing countries; Exchange rate fundamentals; Global vector autoregression; Panel vector error correction model; Real exchange rates; Sign restricted impulse response.
Abstract: This paper investigates international responses of key macroeconomic variables, particularly real exchange rates, to simultaneous shocks to productivity in the traded sector in eight Asian emerging and developing countries. We use panel estimation techniques to construct component submodels in a thirty country global vector autoregressive (GVAR) model. The GVAR approach can account for interaction among all countries and capture many potential international transmission channels. We identify the shocks by using sign restricted impulse responses. We find that increases in traded-sector productivity in Asian developing countries lead to a real appreciation of the domestic currencies, in line with the Balassa-Samuelson hypothesis. Inflation also increases in many Asian developing countries. After the shocks, nontraded sector productivity in the US and other developed countries increases, suggesting that there is a compositional shift in their production, away from the traded goods toward the nontraded goods. This allows productivity in the nontraded sector to increase. Further, the traded sector productivity shocks in Asia stimulate international trade in most countries. 
Classification-JEL: C51, E52, F31
Creation-Date: 2014
Number: 23/14
Length: 
Publication-Status: 
File-URL: http://business.monash.edu/econometrics-and-business-statistics/research/publications/ebs/wp23-14.pdf
File-Format: application/pdf
Handle: RePEc:msh:ebswps:2014-23


Template-type: ReDIF-Paper 1.0
Title: Determination of long-run and short-run dynamics in EC-VARMA models via canonical correlations
Author-Name: George Athanasopoulos
Author-X-Name-First: George
Author-X-Name-Last: Athanasopoulos
Author-Email: George.Athanasopoulos@monash.edu
Author-Name: D.S. Poskitt
Author-X-Name-First: D.S.
Author-X-Name-Last: Poskitt
Author-Email: donald.poskitt@monash.edu
Author-Name: Farshid Vahid
Author-X-Name-First: Farshid
Author-X-Name-Last: Vahid
Author-Email: Farshid.Vahid@monash.edu
Author-Name: Wenying Yao
Author-X-Name-First: Wenying
Author-X-Name-Last: Yao
Author-Email: wenying.yao@utas.edu.au
Keywords: Cointegration, Error correction, Scalar Component Model, Multivariate Time Series.
Abstract: This article studies a simple, coherent approach for identifying and estimating error correcting vector autoregressive moving average (EC-VARMA) models. Canonical correlation analysis is implemented for both determining the cointegrating rank, using a strongly consistent method, and identifying the short-run VARMA dynamics, using the scalar component methodology. Finite sample performances are evaluated via Monte-Carlo simulations and the approach is applied to model and forecast US interest rates. The results reveal that EC-VARMA models generate significantly more accurate out-of-sample forecasts than vector error correction models (VECMs), especially for short horizons.
Classification-JEL: C1, C32, C53
Creation-Date: 2014
Number: 22/14
Length: 
Publication-Status: 
File-URL: http://business.monash.edu/econometrics-and-business-statistics/research/publications/ebs/wp22-14.pdf
File-Format: application/pdf
Handle: RePEc:msh:ebswps:2014-22


Template-type: ReDIF-Paper 1.0
Title: A Model Validation Procedure
Author-Name: Julia Polak
Author-X-Name-First: Julia
Author-X-Name-Last: Polak
Author-Email: Julia.Polak@monash.edu
Author-Name: Maxwell L. King
Author-X-Name-First: Maxwell L.
Author-X-Name-Last: King
Author-Email: Maxwell.King@monash.edu
Author-Name: Xibin Zhang
Author-X-Name-First: Xibin
Author-X-Name-Last: Zhang
Author-Email: Xibin.Zhang@monash.edu
Keywords: Chow test, model validation, p-value, multivariate kernel density estimation, structural break
Abstract: Statistical models can play a crucial role in decision making. Traditional model validation tests typically make restrictive parametric assumptions about the model under the null and the alternative hypotheses. The majority of these tests examine one type of change at a time. This paper presents a method for determining whether new data continues to support the chosen model. We suggest using simulation and the kernel density estimator instead of assuming a parametric distribution for the data under the hull hypothesis. This leads to a more versatile testing procedure, one that can be applied to test different types of models and look for a variety of different types of divergences from the null hypothesis. Such a flexible testing procedure, in some cases, can also replace a range of tests that each test against particular alternative hypotheses. The procedure’s ability to recognize a change in the underlying model is demonstrated through AR(1) and linear models. We examine the power of our procedure to detect changes in the variance of the error term and the AR coefficient in the AR(1) model. In the linear model, we examine the performance of the procedure when there are changes in the error variance and error distribution, and when an economic cycle is introduced into the model. We find that the procedure has correct empirical size and high power to recognize the changes in the data generating process after 10 to 15 new observations, depending on the type and extent of the change.
Classification-JEL: C12, C14, C52, C53
Creation-Date: 2014
Number: 21/14
Length: 
Publication-Status: 
File-URL: http://business.monash.edu/econometrics-and-business-statistics/research/publications/ebs/wp21-14.pdf
File-Format: application/pdf
Handle: RePEc:msh:ebswps:2014-21

Template-type: ReDIF-Paper 1.0
Title: Approximate Bayesian Computation in State Space Models
Author-Name: Gael M. Martin
Author-X-Name-First: Gael M.
Author-X-Name-Last: Martin
Author-Email: Gael.Martin@monash.edu
Author-Name: Brendan P.M. McCabe
Author-X-Name-First: Brendan P.M.
Author-X-Name-Last: McCabe
Author-Email: Brendan.Mccabe@liverpool.ac.uk
Author-Name: Worapree Maneesoonthorn
Author-X-Name-First: Worapree
Author-X-Name-Last: Maneesoonthorn
Author-Email: O.Maneesoonthorn@mbs.edu
Author-Name: Christian P. Robert
Author-X-Name-First: Christian 
Author-X-Name-Last: Robert
Author-Email: Christian.Robert@ceremade.dauphine.fr
Keywords: Likelihood-free methods, latent diffusion models, linear Gaussian state space models, asymptotic sufficiency, unscented Kalman filter, stochastic volatility.
Abstract: A new approach to inference in state space models is proposed, based on approximate Bayesian computation (ABC). ABC avoids evaluation of the likelihood function by matching observed summary statistics with statistics computed from data simulated from the true process; exact inference being feasible only if the statistics are sufficient. With finite sample sufficiency unattainable in the state space setting, we seek asymptotic sufficiency via the maximum likelihood estimator (MLE) of the parameters of an auxiliary model. We prove that this auxiliary model-based approach achieves Bayesian consistency, and that - in a precise limiting sense - the proximity to (asymptotic) sufficiency yielded by the MLE is replicated by the score. In multiple parameter settings a separate treatment of scalar parameters, based on integrated likelihood techniques, is advocated as a way of avoiding the curse of dimensionality. Some attention is given to a structure in which the state variable is driven by a continuous time process, with exact inference typically infeasible in this case as a result of intractable transitions. The ABC method is demonstrated using the unscented Kalman filter as a fast and simple way of producing an approximation in this setting, with a stochastic volatility model for financial returns used for illustration.
Classification-JEL: C11, C22, C58
Creation-Date: 2014
Number: 20/14
Length: 
Publication-Status: 
File-URL: http://business.monash.edu/econometrics-and-business-statistics/research/publications/ebs/wp20-14.pdf
File-Format: application/pdf
Handle: RePEc:msh:ebswps:2014-20

Template-type: ReDIF-Paper 1.0
Title: Bias Correction of Persistence Measures in Fractionally Integrated Models
Author-Name: Simone D. Grose
Author-X-Name-First: Simone D.
Author-X-Name-Last: Grose
Author-Email: Simone.Grose@monash.edu
Author-Name: Gael M. Martin
Author-X-Name-First: Gael M.
Author-X-Name-Last: Martin
Author-Email: Gael.Martin@monash.edu
Author-Name: D.S. Poskitt
Author-X-Name-First: D.S.
Author-X-Name-Last: Poskitt
Author-Email: donald.poskitt@monash.edu
Keywords: Long memory, ARFIMA, sieve bootstrap, bootstrap-based bias correction, sample autocorrelation function, impulse response function.
Abstract: This paper investigates the accuracy of bootstrap-based bias correction of persistence measures for long memory fractionally integrated processes. The bootstrap method is based on the semi-parametric sieve approach, with the dynamics in the long memory process captured by an autoregressive approximation. With a view to improving accuracy, the sieve method is also applied to data pre-filtered by a semi-parametric estimate of the long memory parameter. Both versions of the bootstrap technique are used to estimate the finite sample distributions of the sample autocorrelation coefficients and the impulse response coefficients and, in turn, to bias-adjust these statistics. The accuracy of the resultant estimators in the case of the autocorrelation coefficients is also compared with that yielded by analytical bias adjustment methods when available. The (raw) sieve technique is seen to yield a reduction in the bias of both persistence measures. The pre-filtered sieve produces a substantial further reduction in the bias of the estimated impulse response function, whilst the extra improvement yielded by pre-filtering in the case of the sample autocorrelation function is shown to depend heavily on the accuracy of the pre-filter.
Classification-JEL: C18, C22, C52
Creation-Date: 2014
Number: 19/14
Length: 42
Publication-Status: 
File-URL: http://business.monash.edu/econometrics-and-business-statistics/research/publications/ebs/wp19-14.pdf
File-Format: application/pdf
Handle: RePEc:msh:ebswps:2014-19

Template-type: ReDIF-Paper 1.0
Title: Issues in the Estimation of Mis-Specified Models of Fractionally Integrated Processes
Author-Name: K. Nadarajah
Author-X-Name-First: K.
Author-X-Name-Last: Nadarajah
Author-Email: kanchana.nadarajah@monash.edu 
Author-Name: Gael M. Martin
Author-X-Name-First: Gael M.
Author-X-Name-Last: Martin
Author-Email: Gael.Martin@monash.edu
Author-Name: D.S. Poskitt
Author-X-Name-First: D.S.
Author-X-Name-Last: Poskitt
Author-Email: donald.poskitt@monash.edu
Keywords: nd phrases: bias, conditional sum of squares, frequency domain, long memory models, maximum likelihood, mean squared error, pseudo true parameter, time domain, Whittle.
Abstract: In this paper we quantify the impact of model mis-specification on the properties of parameter estimators applied to fractionally integrated processes. We demonstrate the asymptotic equivalence of four alternative parametric methods: frequency domain maximum likelihood, Whittle estimation, time domain maximum likelihood and conditional sum of squares. We show that all four estimators converge to the same pseudo-true value and provide an analytical representation of their (common) asymptotic distribution. As well as providing theoretical insights, we explore the finite sample properties of the alternative estimators when used to fit mis-specified models. In particular we demonstrate that when the difference between the true and pseudo-true values of the long memory parameter is sufficiently large, a clear distinction between the frequency domain and time domain estimators can be observed - in terms of the accuracy with which the finite sample distributions replicate the common asymptotic distribution - with the time domain estimators exhibiting a closer match overall. Simulation experiments also demonstrate that the two time-domain estimators have the smallest bias and mean squared error as estimators of the pseudo-true value of the long memory parameter, with conditional sum of squares being the most accurate estimator overall and having a relative efficiency that is approximately double that of frequency domain maximum likelihood, across a range of mis-specification designs.
Classification-JEL: C18, C22, C52
Creation-Date: 2014
Number: 18/14
Length: 36
Publication-Status: 
File-URL: http://business.monash.edu/econometrics-and-business-statistics/research/publications/ebs/wp18-14.pdf
File-Format: application/pdf
Handle: RePEc:msh:ebswps:2014-18

Template-type: ReDIF-Paper 1.0 
Title: Fast computation of reconciled forecasts for hierarchical and grouped time series
Author-Name: Rob J Hyndman
Author-X-Name-First: Rob J
Author-X-Name-Last: Hyndman
Author-Email: rob.hyndman@monash.edu
Author-Name: Alan Lee
Author-X-Name-First: Alan
Author-X-Name-Last: Lee
Author-Email: lee@stat.auckland.ac.nz
Author-Name: Earo Wang
Author-X-Name-First: Earo
Author-X-Name-Last: Wang
Author-Email: yiru.wang@monash.edu
Keywords: combining forecasts, grouped time series, hierarchical time series, reconciling forecasts, weighted least squares.
Abstract: We describe some fast algorithms for reconciling large collections of time series forecasts with aggregation constraints. The constraints arise due to the need for forecasts of collections of time series with hierarchical or grouped structures to add up in the same manner as the observed time series. We show that the least squares approach to reconciling hierarchical forecasts can be extended to more general non-hierarchical groups of time series, and that the computations can be handled efficiently by exploiting the structure of the associated design matrix. Our algorithms will reconcile hierarchical forecasts with hierarchies of unlimited size, making forecast reconciliation feasible in business applications involving very large numbers of time series.
Classification-JEL: C32, C53, C55, C63
Creation-Date: 2014
Number: 17/14
Length: 26
Publication-Status: 
File-URL: http://business.monash.edu/econometrics-and-business-statistics/research/publications/ebs/wp17-14.pdf
File-Format: application/pdf
Handle: RePEc:msh:ebswps:2014-17


Template-type: ReDIF-Paper 1.0
Title: Low-dimensional decomposition, smoothing and forecasting of sparse functional data
Author-Name: Alexander Dokumentov
Author-X-Name-First: Alexander
Author-X-Name-Last: Dokumentov
Author-Email: alexander.dokumentov@monash.edu
Author-Name: Rob J Hyndman
Author-X-Name-First: Rob J
Author-X-Name-Last: Hyndman
Author-Email: rob.hyndman@monash.edu
Keywords: Tikhonov regularisation, Smoothing, Forecasting, Ridge regression, PCA, LASSO, Maximum-margin matrix factorisation, Mortality rates, Sparse longitudinal data
Abstract: We propose a new generic method ROPES (Regularized Optimization for Prediction and Estimation with Sparse data) for decomposing, smoothing and forecasting two-dimensional sparse data. In some ways, ROPES is similar to Ridge Regression, the LASSO, Principal Component Analysis (PCA) and Maximum-Margin Matrix Factorisation (MMMF). Using this new approach, we propose a practical method of forecasting mortality rates, as well as a new method for interpolating and extrapolating sparse longitudinal data. We also show how to calculate prediction intervals for the resulting estimates.
Classification-JEL: C10, C14, C33
Creation-Date: 2014
Number: 16/14
Length: 33
Publication-Status: 
File-URL: http://business.monash.edu/econometrics-and-business-statistics/research/publications/ebs/wp16-14.pdf
File-Format: application/pdf
Handle: RePEc:msh:ebswps:2014-16


Template-type: ReDIF-Paper 1.0
Title: Semiparametric Model Selection in Panel Data Models with Deterministic Trends and Cross-Sectional Dependence
Author-Name: Jia Chen
Author-X-Name-First: Jia
Author-X-Name-Last: Chen
Author-Email: jia.chen@york.ac.uk 
Author-Name: Jiti Gao
Author-X-Name-First: Jiti
Author-X-Name-Last: Gao
Author-Email: Jiti.Gao@monash.edu
Keywords: Cross-sectional dependence, fixed effects, large panel, local linear fitting, penalty function, profile likelihood, semiparametric regression.
Abstract: In this paper, we consider a model selection issue in semiparametric panel data models with fixed effects. The modelling framework under investigation can accommodate both nonlinear deterministic trends and cross-sectional dependence. And we consider the so-called "large panels" where both the time series and cross sectional sizes are very large. A penalised profile least squares method with first-stage local linear smoothing is developed to select the significant covariates and estimate the regression coefficients simultaneously. The convergence rate and the oracle property of the resulting semiparametric estimator are established by the joint limit approach. The developed semiparametric model selection methodology is illustrated by two Monte-Carlo simulation studies, where we compare the performance in model selection and estimation of three penalties, i.e., the least absolute shrinkage and selection operator (LASSO), the smoothly clipped absolute deviation (SCAD), and the minimax concave penalty (MCP).
Classification-JEL: C13, C14, C23
Creation-Date: 2014
Number: 15/14
Length: 36
Publication-Status: 
File-URL: http://business.monash.edu/econometrics-and-business-statistics/research/publications/ebs/wp15-14.pdf
File-Format: application/pdf
Handle: RePEc:msh:ebswps:2014-15


Template-type: ReDIF-Paper 1.0
Title: Semiparametric Localized Bandwidth Selection in Kernel Density Estimation
Author-Name: Tingting Cheng
Author-X-Name-First: Tingting
Author-X-Name-Last: Cheng
Author-Email: Tingting.Cheng@monash.edu
Author-Name: Jiti Gao
Author-X-Name-First: Jiti
Author-X-Name-Last: Gao
Author-Email: Jiti.Gao@monash.edu
Author-Name: Xibin Zhang
Author-X-Name-First: Xibin
Author-X-Name-Last: Zhang
Author-Email: Xibin.Zhang@monash.edu
Keywords: hyperparameter estimation; likelihood score; localized bandwidth.
Abstract: Since conventional cross-validation bandwidth selection methods do not work for the case where the data considered are serially dependent, alternative bandwidth selection methods are needed. In recent years, Bayesian based global bandwidth selection methods have been proposed. Our experience shows that the use of a global bandwidth is however less suitable than using a localized bandwidth in kernel density estimation in the case where the data are serially dependent. Nonetheless, a difficult issue is how we can consistently estimate a localized bandwidth. In this paper, we propose a semiparametric estimation method and establish an asymptotic theory for the proposed estimator. A by-product of this bandwidth estimate is a new sampling-based likelihood approach to hyperparameter estimation. Monte Carlo simulation studies show that the proposed hyperparameter estimation method works very well, and that the proposed bandwidth estimator outperforms its competitors. Applications of the new bandwidth estimator to the kernel density estimation of Eurodollar deposit rate, as well as the S&P 500 daily return under conditional heteroscedasticity, demonstrate the effectiveness and competitiveness of the proposed semiparametric localized bandwidth.
Classification-JEL: C13, C14, C21
Creation-Date: 2014
Number: 14/14
Length: 46
Publication-Status: 
File-URL: http://business.monash.edu/econometrics-and-business-statistics/research/publications/ebs/wp14-14.pdf
File-Format: application/pdf
Handle: RePEc:msh:ebswps:2014-14


Template-type: ReDIF-Paper 1.0
Title: Boosting multi-step autoregressive forecasts
Author-Name: Souhaib Ben Taieb
Author-X-Name-First: Souhaib Ben
Author-X-Name-Last: Taieb
Author-Email: sbentaie@ulb.ac.be
Author-Name: Rob J Hyndman
Author-X-Name-First: Rob
Author-X-Name-Last: Hyndman
Author-Email: Rob.Hyndman@monash.edu
Keywords: Multi-step forecasting; forecasting strategies; recursive forecasting; direct forecasting; linear time series; nonlinear time series; boosting
Abstract: Multi-step forecasts can be produced recursively by iterating a one-step model, or directly using a specific model for each horizon. Choosing between these two strategies is not an easy task since it involves a trade-off between bias and estimation variance over the forecast horizon. Using a nonlinear machine learning model makes the tradeoff even more difficult. To address this issue, we propose a new forecasting strategy which boosts traditional recursive linear forecasts with a direct strategy using a boosting autoregression procedure at each horizon. First, we investigate the performance of the proposed strategy in terms of bias and variance decomposition of the error using simulated time series. Then, we evaluate the proposed strategy on real-world time series from two forecasting competitions. Overall, we obtain excellent performance with respect to the standard forecasting strategies.
Classification-JEL: C22, C53, C14
Creation-Date: 2014
Number: 13/14
Length: 10
Publication-Status: 
File-URL: http://business.monash.edu/econometrics-and-business-statistics/research/publications/ebs/wp13-14.pdf
File-Format: application/pdf
Handle: RePEc:msh:ebswps:2014-13


Template-type: ReDIF-Paper 1.0
Title: Efficient Identification of the Pareto Optimal Set
Author-Name: Ingrida Steponavice
Author-X-Name-First: Ingrida
Author-X-Name-Last: Steponavice
Author-Email: ingrida.steponavice@monash.edu
Author-Name: Rob J Hyndman
Author-X-Name-First: Rob
Author-X-Name-Last: Hyndman
Author-Email: Rob.Hyndman@monash.edu
Author-Name: Kate Smith-Miles
Author-X-Name-First: Kate
Author-X-Name-Last: Smith-Miles
Author-Email:  kate.smith-miles@monash.edu
Author-Name: Laura Villanova
Author-X-Name-First: Laura
Author-X-Name-Last: Villanova
Author-Email: Laura.Villanova@monash.edu
Keywords: multiobjective optimization, classification, expensive black-box function
Abstract: In this paper, we focus on expensive multiobjective optimization problems and propose a method to predict an approximation of the Pareto optimal set using classification of sampled decision vectors as dominated or nondominated. The performance of our method, called EPIC, is demonstrated on a set of benchmark problems used in the multiobjective optimization literature and compared with state-of the-art methods, ParEGO and PAL. The initial results are promising and encourage further research in this direction.
Classification-JEL: C61, C90, C44
Creation-Date: 2014
Number: 12/14
Length: 13
Publication-Status: 
File-URL: http://business.monash.edu/econometrics-and-business-statistics/research/publications/ebs/wp12-14.pdf
File-Format: application/pdf
Handle: RePEc:msh:ebswps:2014-12


Template-type: ReDIF-Paper 1.0
Title: Bagging Exponential Smoothing Methods using STL Decomposition and Box-Cox Transformation
Author-Name: Christoph Bergmeir
Author-X-Name-First: Christoph
Author-X-Name-Last: Bergmeir
Author-Email: c.bergmeir@decsai.ugr.es
Author-Name: Rob J Hyndman
Author-X-Name-First: Rob J
Author-X-Name-Last: Hyndman
Author-Email: Rob.Hyndman@monash.edu
Author-Name: Jose M Benitez 
Author-X-Name-First: Jose M Benitez
Author-X-Name-Last: C22, C53, C63
Author-Email: 
Keywords: bagging, bootstrapping, exponential smoothing, STL decomposition.
Abstract: Exponential smoothing is one of the most popular forecasting methods. We present a method for bootstrap aggregation (bagging) of exponential smoothing methods. The bagging uses a Box-Cox transformation followed by an STL decomposition to separate the time series into trend, seasonal part, and remainder. The remainder is then bootstrapped using a moving block bootstrap, and a new series is assembled using this bootstrapped remainder. On the bootstrapped series, an ensemble of exponential smoothing models is estimated. The resulting point forecasts are averaged using the mean. We evaluate this new method on the M3 data set, showing that it consistently outperforms the original exponential smoothing models. On the monthly data, we achieve better results than any of the original M3 participants. We also perform statistical testing to explore significance of the results. Using the MASE, our method is significantly better than all the M3 participants on the monthly data.
Classification-JEL: 
Creation-Date: 2014
Number: 11/14
Length: 21
Publication-Status: 
File-URL: http://business.monash.edu/econometrics-and-business-statistics/research/publications/ebs/wp11-14.pdf
File-Format: application/pdf
Handle: RePEc:msh:ebswps:2014-11


Template-type: ReDIF-Paper 1.0
Title: Bias Reduction of Long Memory Parameter Estimators via the Pre-filtered Sieve Bootstrap
Author-Name: D.S. Poskitt
Author-X-Name-First: D.S.
Author-X-Name-Last: Poskitt
Author-Email: donald.poskitt@monash.edu
Author-Name: Gael M. Martin
Author-X-Name-First: Gael M.
Author-X-Name-Last: Martin
Author-Email: Gael.Martin@monash.edu
Author-Name: Simone D. Grose
Author-X-Name-First: Simone D.
Author-X-Name-Last: Grose
Author-Email: Simone.Grose@monash.edu
Keywords: nd phrases: Bias adjustment, bootstrap-based inference, fractional process, log-periodogram regression, local Whittle estimator
Abstract: This paper investigates the use of bootstrap-based bias correction of semi-parametric estimators of the long memory parameter in fractionally integrated processes. The re-sampling method involves the application of the sieve boot-strap to data pre-filtered by a preliminary semi-parametric estimate of the long memory parameter. Theoretical justification for using the bootstrap techniques to bias adjust log-periodogram and semi-parametric local Whittle estimators of the memory parameter is provided. Simulation evidence comparing the performance of the bootstrap bias correction with analytical bias correction techniques is also presented. The bootstrap method is shown to produce notable bias reductions, in particular when applied to an estimator for which analytical adjustments have already been used. The empirical coverage of confidence intervals based on the bias-adjusted estimators is very close to the nominal, for a reasonably large sample size, more so than for the comparable analytically adjusted estimators. The precision of inferences (as measured by interval length) is also greater when the bootstrap is used to bias correct rather than analytical adjustments.
Classification-JEL:  C18, C22, C52
Creation-Date: 2014
Number: 10/14
Length: 39
Publication-Status: 
File-URL: http://business.monash.edu/econometrics-and-business-statistics/research/publications/ebs/wp10-14.pdf
File-Format: application/pdf
Handle: RePEc:msh:ebswps:2014-10

Template-type: ReDIF-Paper 1.0
Title: Semiparametric Single-Index Panel Data Models with Cross-Sectional Dependence
Author-Name: Bin Peng
Author-X-Name-First: Bin
Author-X-Name-Last: Peng
Author-Email: pengbin430@gmail.com
Author-Name: Chaohua Dong
Author-X-Name-First: Chaohua
Author-X-Name-Last: Dong
Author-Email: Chaohua.Dong@monash.edu
Author-Name: Jiti Gao
Author-X-Name-First: Jiti
Author-X-Name-Last: Gao
Author-Email: Jiti.Gao@monash.edu
Keywords: symptotic theory; closed-form estimate; nonlinear panel data model; orthogonal series method
Abstract: In this paper, we consider a semiparametric single index panel data mode with cross-sectional dependence, high-dimensionality and stationarity. Meanwhile, we allow fixed effects to be correlated with the regressors to capture unobservable heterogeneity. Under a general spatial error dependence structure, we then establish some consistent closed-form estimates for both the unknown parameters and a link function for the case where both N and T go to ∞. Rates of convergence and asymptotic normality consistencies are established for the proposed estimates. Our experience suggests that the proposed estimation method is simple and thus attractive for finite-sample studies and empirical implementations. Moreover, both the finite-sample performance and the empirical applications show that the proposed estimation method works well when the cross-sectional dependence exists in the data set.
Classification-JEL: C13, C14, C23
Creation-Date: 2014
Number: 9/14
Length: 39
Publication-Status: 
File-URL: http://business.monash.edu/econometrics-and-business-statistics/research/publications/ebs/wp09-14.pdf
File-Format: application/pdf
Handle: RePEc:msh:ebswps:2014-9

Template-type: ReDIF-Paper 1.0
Title: Specification Testing for Nonlinear Multivariate Cointegrating Regressions
Author-Name: Chaohua Dong
Author-X-Name-First: Chaohua
Author-X-Name-Last: Dong
Author-Email: Chaohua.Dong@monash.edu
Author-Name: Jiti Gao
Author-X-Name-First: Jiti
Author-X-Name-Last: Gao
Author-Email: Jiti.Gao@monash.edu
Author-Name: Dag Tjostheim
Author-X-Name-First: Dag
Author-X-Name-Last: Tj&#248;stheim
Author-Email: Dag.Tjostheim@math.uib.no
Author-Name: Jiying Yin
Author-X-Name-First: Jiying
Author-X-Name-Last: Yin
Author-Email: Jiying.Yin@monash.edu
Keywords: ointegration, endogeneity, nonparametric kernel estimation, parametric model speci-fication, time series.
Abstract: This paper considers a general model specification test for nonlinear multivariate cointegrating regressions where the regressor consists of a univariate integrated time series and a vector of stationary time series. The regressors and the errors are generated from the same innovations, so that the model accommodates endogeniety. A new and simple test is proposed and the resulting asymptotic theory is established. The test statistic is constructed based on a natural distance function between a nonparametric estimate and a smoothed parametric counterpart. The asymptotic distribution of the test statistic under the parametric specification is proportional to that of a local-time random variable with a known distribution. In addition, the finite sample performance of the proposed test is evaluated through using both simulated and real data examples.
Classification-JEL: C12, C14, C22
Creation-Date: 2014
Number: 8/14
Length: 44
Publication-Status: 
File-URL: http://business.monash.edu/econometrics-and-business-statistics/research/publications/ebs/wp08-14.pdf
File-Format: application/pdf
Handle: RePEc:msh:ebswps:2014-8

Template-type: ReDIF-Paper 1.0
Title: Estimation for Single-index and Partially Linear Single-index Nonstationary Time Series Models
Author-Name: Chaohua Dong
Author-X-Name-First: Chaohua
Author-X-Name-Last: Dong
Author-Email: Chaohua.Dong@monash.edu
Author-Name: Jiti Gao
Author-X-Name-First: Jiti
Author-X-Name-Last: Gao
Author-Email: Jiti.Gao@monash.edu
Author-Name: Dag Tjostheim
Author-X-Name-First: Dag
Author-X-Name-Last: Tjostheim
Author-Email: Dag.Tjostheim@math.uib.no
Keywords: onstationarity, orthogonal series expansion, single-index models, partially linear single-index models, dual convergence rates, a trio of convergence rates.
Abstract: Estimation in two classes of popular models, single-index models and partially linear single-index models, is studied in this paper. Such models feature nonstationarity. Orthogonal series expansion is used to approximate the unknown integrable link function in the models and a profile approach is used to derive the estimators. The findings include dual convergence rates of the estimators for the single-index models and a trio of convergence rates for the partially linear single-index models. More precisely, the estimators for single-index model converge along the direction of the true parameter vector at rate of n^(-1/4), while at rate of n^(-3/4) along all directions orthogonal to the true parameter vector; on the other hand, the estimators of the index vector for the partially single-index model retain the dual convergence rates as in the single-index model but the estimators of the coefficients in the linear part of the model possess rate 
n^(-1). Monte Carlo simulation verifies these theoretical results. An empirical study on the dataset of aggregate disposable income, consumption, investment and real interest rate in the United States between 1960:1-2009:3 furnishes an application of the proposed estimation procedures in practice.
Classification-JEL:  C13, C14, C32
Creation-Date: 2014
Number: 7/14
Length: 77
Publication-Status: 
File-URL: http://business.monash.edu/econometrics-and-business-statistics/research/publications/ebs/wp07-14.pdf
File-Format: application/pdf
Handle: RePEc:msh:ebswps:2014-7


Template-type: ReDIF-Paper 1.0
Title: A Class of Demand Systems Satisfying Global Regularity and Having Complete Rank Flexibility
Author-Name: Keith R. McLaren
Author-X-Name-First: Keith R.
Author-X-Name-Last: McLaren
Author-Email: Keith.McLaren@monash.edu
Author-Name: Ou Yang
Author-X-Name-First: Ou
Author-X-Name-Last: Yang
Author-Email: Ou.Yang@monash.edu
Keywords: Demand systems; Global regularity; Complete rank flexibility; Duality theory; Indirect utility function
Abstract: A class of demand systems based on simple parametric specification of the indirect utility functions, but allowing for the parsimonious imposition of global regularity, is proposed. Demand systems in this class are completely flexible in rank, i.e., can be potentially specified to acquire as large a rank as required in empirical work. They also exhibit a clear and reasonable homothetic asymptotic behaviour. In an empirical application using Australian data, several examples from this class are estimated and compared with some popular alternatives in the literature.
Classification-JEL: D11, D12 
Creation-Date: 2014
Number: 6/14
Length: 28
Publication-Status: 
File-URL: http://business.monash.edu/econometrics-and-business-statistics/research/publications/ebs/wp06-14.pdf
File-Format: application/pdf
Handle: RePEc:msh:ebswps:2014-6

Template-type: ReDIF-Paper 1.0
Title: Econometric Modelling of Price Response by Alcohol Types to Inform Alcohol Tax Policies
Author-Name: Preety Srivastava
Author-X-Name-First: Preety
Author-X-Name-Last: Srivastava
Author-Email: preety.srivastava@rmit.edu.au
Author-Name: Keith R. McLaren
Author-X-Name-First: Keith R.
Author-X-Name-Last: McLaren
Author-Email: Keith.McLaren@monash.edu
Author-Name: Michael Wohlgenant
Author-X-Name-First: Michael
Author-X-Name-Last: Wohlgenant
Author-Email: michael_wohlgenant@ncsu.edu
Author-Name: Xueyan Zhao
Author-X-Name-First: Xueyan
Author-X-Name-Last: Zhao
Author-Email: Xueyan.Zhao@monash.edu
Keywords: alcohol, demand system, elasticities, semiflexible AIDS, tax.
Abstract: The paper presents estimates of price elasticities of demand for twelve disaggregated alcohol beverages in Australia: premium beer, full strength beer, low alcohol beer, and mid strength beer; red bottled wine, white bottled wine, sparkling wine, cask wine, and dark and light ready-to-drink (RTD); and dark and light spirits. These disaggregated categories correspond closely to the commodities of interest to public policymakers with respect to taxation and health policies. The system of demand equations is estimated with Nielsen data from Australia using the semiflexible AIDS model in order to impose negative semidefiniteness on the demand parameters. Results indicate elastic own-price elasticities for virtually all commodities. Morishma elasticities of substitution indicate premium beer, mid strength beer, and cask wine exhibit the largest elasticities of substitution. Low alcohol beer, light RTD, and light spirits show the lowest substitution. The elasticity estimates are used to illustrate the effect of a change in the current tax system toward taxation equalisation based on alcohol content. The policy simulation highlights the importance of having a complete system of demand elasticities because the mix of consumption of alcohol beverages changes in response to the type of alcohol policy.
Classification-JEL: C3, D11, D12, I1
Creation-Date: 2014
Number: 5/14
Length: 30
Publication-Status: 
File-URL: http://business.monash.edu/econometrics-and-business-statistics/research/publications/ebs/wp05-14.pdf
File-Format: application/pdf
Handle: RePEc:msh:ebswps:2014-5


Template-type: ReDIF-Paper 1.0
Title: Consumer Demand, Consumption, and Asset Pricing: An Integrated Analysis
Author-Name: H. Youn Kim
Author-X-Name-First: H. Youn
Author-X-Name-Last: Kim
Author-Email: youn.kim@wku.edu
Author-Name: Keith R. McLaren
Author-X-Name-First: Keith R.
Author-X-Name-Last: McLaren
Author-Email: Keith.McLaren@monash.edu
Author-Name: K.K. Gary Wong
Author-X-Name-First: K.K. Gary
Author-X-Name-Last: Wong
Author-Email: garywong@umac.mo
Keywords: Intertemporal two-stage budgeting; Indirect utility function; Risk aversion; The stochastic discount factor; Consumption-based CAPM
Abstract: This paper integrates seemingly disjoint studies on consumer behavior in micro and macro analyses via the intertemporal two-stage budgeting procedure with durable goods and liquidity constraints. The model accounts for the influences of nondurables consumption, commodity prices, and durables stock on commodity demands as well as on risk aversion and asset returns. The demand functions for six nondurable goods are jointly estimated with the Euler equations for bonds, shares, and durables goods, with allowance for liquidity constraints. The integrated model proves useful with new findings for risk aversion and, particularly, an extended consumption CAPM with multiple goods and liquidity constraints.
Classification-JEL: D12, E21, G12 
Creation-Date: 2014
Number: 4/14
Length: 48
Publication-Status: 
File-URL: http://business.monash.edu/econometrics-and-business-statistics/research/publications/ebs/wp04-14.pdf
File-Format: application/pdf
Handle: RePEc:msh:ebswps:2014-4


Template-type: ReDIF-Paper 1.0
Title: On The Theory and Practice of Singular Spectrum Analysis Forecasting
Author-Name: M. Atikur Rahman Khan
Author-X-Name-First: M. Atikur Rahman
Author-X-Name-Last: Khan
Author-Email: atikur.khan@monash.edu
Author-Name: D.S. Poskitt
Author-X-Name-First: D.S.
Author-X-Name-Last: Poskitt
Author-Email: donald.poskitt@monash.edu
Keywords: Linear recurrent formula, Mean squared forecast error, Signal dimension, Window length.
Abstract: Theoretical results on the properties of forecasts obtained using singular spectrum analysis are presented in this paper. The mean squared forecast error is derived under broad regularity conditions, and it is shown that the forecasts obtained in practice will converge to their population ensemble counterparts. The theoretical results are illustrated by examining the performance of singular spectrum analysis forecasts when applied to autoregressive processes and a random walk process. Simulation experiments suggest that the asymptotic properties developed are reflected in observed finite sample behaviour. Empirical applications using real world data sets indicate that forecasts based on singular spectrum analysis are competitive with other methods currently in vogue.
Classification-JEL: C51, C52, C53
Creation-Date: 2014
Number: 3/14
Length: 25
Publication-Status: 
File-URL: http://business.monash.edu/econometrics-and-business-statistics/research/publications/ebs/wp04-14.pdf
File-Format: application/pdf
Handle: RePEc:msh:ebswps:2014-3


Template-type: ReDIF-Paper 1.0
Title: Specification Testing in Structural Nonparametric Cointegration
Author-Name: Chaohua Dong
Author-X-Name-First: Chaohua
Author-X-Name-Last: Dong
Author-Email: Chaohua.Dong@monash.edu
Author-Name: Jiti Gao
Author-X-Name-First: Jiti
Author-X-Name-Last: Gao
Author-Email: Jiti.Gao@monash.edu
Keywords: Consumption-income model; Endogeneity; Integrated time series; Linear process; Orthogonal series estimation; Parametric specification
Abstract: This paper proposes two simple and new specification tests based on the use of an orthogonal series for a considerable class of cointegrated time series models with endogeneity and nonsta-tionarity. The paper then establishes an asymptotic theory for each of the proposed tests. The first test is initially proposed for the case where the regression function involved is integrable, which fills a gap in the literature, and the second test is an extended version of the first test for covering a class of non-integrable functions. Endogeneity in two general forms is allowed in the models to be tested. A potential global departure in the alternative hypothesis, which is being overlooked by the literature, is investigated. The finite sample performance of the proposed tests is examined through using several simulated examples. Meanwhile, the second test is naturally applicable to the case where there is a type of endogeneity inherited in the relationship between the United States aggregate consumers' consumption expenditure and disposable income over the period of 1960-2009. Our experience generally shows that the proposed tests are easily implementable and also have stable sizes and good power properties even when the 'distance' between the null hypothesis and a sequence of local alternatives is asymptotically negligible.
Classification-JEL: C12, C14
Creation-Date: 2014
Number: 2/14
Length: 65
Publication-Status: 
File-URL: http://business.monash.edu/econometrics-and-business-statistics/research/publications/ebs/wp02-14.pdf
File-Format: application/pdf
Handle: RePEc:msh:ebswps:2014-2

Template-type: ReDIF-Paper 1.0
Title: Econometric Time Series Specification Testing in a Class of Multiplicative Error Models
Author-Name: Patrick W Saart
Author-X-Name-First: Patrick W
Author-X-Name-Last: Saart
Author-Email:  patrick.wsaart@canterbury.ac.nz
Author-Name: Jiti Gao
Author-X-Name-First: Jiti
Author-X-Name-Last: Gao
Author-Email: Jiti.Gao@monash.edu
Author-Name: Nam Hyun Kim
Author-X-Name-First: Nam Hyun
Author-X-Name-Last: Kim
Author-Email: nam-hyun.kim@uni-konstanz.de
Keywords: Financial duration process; Nonnegative time series; Nonparametric kernel estimation; Semiparametric mixture model
Abstract: In recent years, analysis of financial time series has focused largely on data related to market trading activity. Apart from modelling the conditional variance of returns within the GARCH family of models, presently attention has also been devoted to other market variables, especially volumes, number of trades and durations. The financial econometrics literature has focused on Multiplicative Error Models (MEMs), which are considered particularly suited for modelling certain financial variables. The paper establishes an econometric specification approach for MEMs. In the literature, several procedures are available to perform specification testing for MEMs, but the proposed specification testing method is particularly useful within the context of the MEMs of financial duration. The paper makes a number of important theoretical contributions. Both the proposed specification testing method and the associated theory are established and evaluated through simulations and real data examples.
Classification-JEL: C14, C41, F31
Creation-Date: 2014
Number: 1/14
Length: 44
Publication-Status: 
File-URL: http://business.monash.edu/econometrics-and-business-statistics/research/publications/ebs/wp01-14.pdf
File-Format: application/pdf
Handle: RePEc:msh:ebswps:2014-1




